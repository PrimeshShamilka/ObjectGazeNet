{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import cv2\n",
    "\n",
    "from utils_logging import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose between Recasens or GazeNet\n",
    "\n",
    "- Idea is you can just swap \n",
    "models.recasens, dataloader.recasens, training.train_recasens, etc...\n",
    "- with the following\n",
    "models.gazenet, dataloader.gazenet, training.train_gazenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from models.chong import ModelSpatial\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.chong import GazeDataset, GooDataset\n",
    "from dataloader import chong_imutils\n",
    "from training.train_chong import train, test, GazeOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger will save the training and test errors to a .log file \n",
    "logger = setup_logger(name='first_logger',\n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train_chong_gooreal.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataloaders\n",
    "- Choose between GazeDataset (Gazefollow dataset) or GooDataset (GooSynth/GooReal)\n",
    "- Set paths to image directories and pickle paths. For Gazefollow, images_dir and test_images_dir should be the same and both lead to the path containing the train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 172800\n",
      "Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Synth\n",
    "batch_size=32\n",
    "workers=12\n",
    "\n",
    "images_dir = '/hdd/HENRI/goosynth/1person/GazeDatasets/'\n",
    "pickle_path = '/hdd/HENRI/goosynth/picklefiles/trainpickle2to19human.pickle'\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2450\n",
      "Number of Images: 2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Real\n",
    "batch_size=4\n",
    "workers=12\n",
    "\n",
    "images_dir = '/home/shashimal/Desktop/gooreal/finalrealdatasetImgsV2/'\n",
    "pickle_path = '/home/shashimal/Desktop/gooreal/oneshotrealhumansNew.pickle'\n",
    "test_images_dir = '/home/shashimal/Desktop/gooreal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/shashimal/Desktop/gooreal/testrealhumansNew.pickle'\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for GAZE\n",
    "\n",
    "batch_size=32\n",
    "workers=12\n",
    "testbatchsize=16\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat'\n",
    "\n",
    "train_set = GazeDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GazeDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Model and Set Training Hyperparameters\n",
    "- For Gazefollow, the model requires the alexnet_places365 pretrained model, provided here: https://urlzs.com/ytKK3\n",
    "- When resuming training, set to True and set the resume_path for the saved model.\n",
    "- Here, logging module is initialized (logger) to save training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Constructing model\n",
      "==> Loading initial weights\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/s9y65ajzjz4thve/initial_weights_for_spatial_training.pt\n",
    "init_weights = 'initial_weights_for_spatial_training.pt'\n",
    "\n",
    "# Loads model\n",
    "print(\"==> Constructing model\")\n",
    "net = ModelSpatial()\n",
    "net.cuda()\n",
    "\n",
    "# Hyperparameters\n",
    "start_epoch = 0\n",
    "max_epoch = 5\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Initial weights chong\n",
    "print(\"==> Loading initial weights\")\n",
    "model_dict = net.state_dict()\n",
    "pretrained_dict = torch.load(init_weights)\n",
    "pretrained_dict = pretrained_dict['model']\n",
    "model_dict.update(pretrained_dict)\n",
    "net.load_state_dict(model_dict)\n",
    "\n",
    "# Initializes Optimizer\n",
    "gaze_opt = GazeOptimizer(net, learning_rate)\n",
    "optimizer = gaze_opt.getOptimizer(start_epoch)\n",
    "\n",
    "# Resuming Training\n",
    "resume_training = False\n",
    "resume_path = './saved_models/chong_goosynth/model_epoch25.pth.tar'\n",
    "if resume_training:\n",
    "    net, optimizer, _ = resume_checkpoint(net, optimizer,resume_path)\n",
    "    test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "  0%|          | 0/1073 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33190/3165974362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/GOO-GAZE2021/gazefollowing/training/train_chong.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net, test_data_loader, logger, save_output)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mval_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_face\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_head_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gaze_heatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_inside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mval_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 8)"
     ]
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the Model\n",
    "- Determine in which epochs do you want to save the model, as you might not want to save every epoch\n",
    "- Training and test errors can be accessed in the logs directory set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "  0%|          | 0/613 [00:00<?, ?it/s]/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      " 16%|█▌        | 99/613 [03:56<19:47,  2.31s/it]68.91891025543212\n",
      " 32%|███▏      | 199/613 [07:43<15:50,  2.30s/it]68.11870040893555\n",
      " 49%|████▉     | 299/613 [11:26<10:08,  1.94s/it]67.11412971496583\n",
      " 65%|██████▌   | 399/613 [14:48<07:56,  2.23s/it]66.19479419708252\n",
      " 81%|████████▏ | 499/613 [18:35<04:16,  2.25s/it]66.49509391784667\n",
      " 98%|█████████▊| 599/613 [21:58<00:26,  1.92s/it]65.8030415725708\n",
      "100%|██████████| 613/613 [22:25<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 99/613 [03:13<16:32,  1.93s/it]65.58567909240723\n",
      " 32%|███▏      | 199/613 [06:26<13:19,  1.93s/it]65.08650608062744\n",
      " 49%|████▉     | 299/613 [09:39<10:03,  1.92s/it]64.79565208435059\n",
      " 65%|██████▌   | 399/613 [12:52<06:51,  1.92s/it]64.39537612915039\n",
      " 81%|████████▏ | 499/613 [16:04<03:38,  1.92s/it]65.25406341552734\n",
      " 98%|█████████▊| 599/613 [19:16<00:26,  1.92s/it]64.75374084472656\n",
      "100%|██████████| 613/613 [19:43<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 99/613 [03:13<16:26,  1.92s/it]64.12285961151123\n",
      " 32%|███▏      | 199/613 [06:26<13:16,  1.92s/it]64.52913795471191\n",
      " 49%|████▉     | 299/613 [09:38<10:00,  1.91s/it]63.733947868347165\n",
      " 65%|██████▌   | 399/613 [12:52<07:20,  2.06s/it]63.739145545959474\n",
      " 81%|████████▏ | 499/613 [16:00<03:33,  1.87s/it]64.12066928863526\n",
      " 98%|█████████▊| 599/613 [19:08<00:26,  1.87s/it]63.93507568359375\n",
      "100%|██████████| 613/613 [19:34<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 99/613 [03:06<16:01,  1.87s/it]64.13455711364746\n",
      " 32%|███▏      | 199/613 [06:14<12:54,  1.87s/it]63.66544696807861\n",
      " 49%|████▉     | 299/613 [09:21<09:47,  1.87s/it]63.89187271118164\n",
      " 65%|██████▌   | 399/613 [12:30<06:39,  1.87s/it]63.60672634124756\n",
      " 81%|████████▏ | 499/613 [15:37<03:33,  1.87s/it]63.72061542510986\n",
      " 98%|█████████▊| 599/613 [18:50<00:26,  1.87s/it]63.89179275512695\n",
      "100%|██████████| 613/613 [19:16<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "best_l2 = np.inf\n",
    "\n",
    "for epoch in range(1,5):\n",
    "\n",
    "    # Update optimizer\n",
    "    optimizer = gaze_opt.getOptimizer(epoch)\n",
    "\n",
    "    # Train model\n",
    "    print('training')\n",
    "    train(net, train_data_loader, optimizer, epoch, logger)\n",
    "\n",
    "    # Evaluate model\n",
    "    #scores = test(net, test_data_loader, logger)\n",
    "    \n",
    "    # Save model+optimizer with best L2 Scorehttp://localhost:8888/notebooks/train_chong.ipynb#\n",
    "    #if scores[1] < best_l2:\n",
    "    #    best_l2 = scores[1]\n",
    "    #    save_path = './saved_models/chong_gooreal_notrained/'\n",
    "    #    save_checkpoint(net, optimizer, 420, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:16<00:00,  8.39it/s]\n",
      "average error: [0.8613018095794566, 0.1459625192366771, 26.391563159013245]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8613018095794566, 0.1459625192366771, 26.391563159013245]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'chong.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'chong_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread('/home/shashimal/Downloads/cam00000_img00000.jpg', cv2.IMREAD_COLOR)\n",
    "print(image.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}