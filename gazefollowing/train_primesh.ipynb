{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import cv2\n",
    "\n",
    "from utils_logging import setup_logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models.shashimal2 import Shashimal2\n",
    "from models.primesh import Primesh\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "#from dataloader.shashimal2_synth import GooDataset\n",
    "from dataloader.shashimal2 import GooDataset\n",
    "from dataloader.shashimal2 import GazeDataset\n",
    "from dataloader import chong_imutils\n",
    "from training.train_primesh import train, GazeOptimizer, train_with_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logger = setup_logger(name='first_logger',\n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train_chong_gooreal.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Number of Images: 2450\n",
      "Test\n",
      "Number of Images: 2146\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Real\n",
    "batch_size=4\n",
    "workers=12\n",
    "images_dir = '/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/Datasets/gooreal/finalrealdatasetImgsV2'\n",
    "pickle_path = '/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/Datasets/gooreal/oneshotrealhumansNew.pickle'\n",
    "test_images_dir = '/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/Datasets/gooreal/finalrealdatasetImgsV2'\n",
    "test_pickle_path = '/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/Datasets/gooreal/testrealhumansNew.pickle'\n",
    "\n",
    "print ('Train')\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [2000, 450])\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "val_data_loader = DataLoader(dataset=val_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "print ('Test')\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft2 = Primesh()\n",
    "\n",
    "\n",
    "model_ft2 = model_ft2.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss().cuda()\n",
    "# criterion\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "start_epoch = 0\n",
    "max_epoch = 5\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Initializes Optimizer\n",
    "gaze_opt = GazeOptimizer(model_ft2, learning_rate)\n",
    "optimizer = gaze_opt.getOptimizer(start_epoch)\n",
    "if False:\n",
    "    checkpoint_fpath = '/gdrive/MyDrive/shashimal2_gazefollow_chechkpoint1.pt'\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model_ft2.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-929304219a7d7600\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-929304219a7d7600\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/primesh')\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/code/ObjectGazeNet/gazefollowing/runs\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [01:53<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5] valid_loss: 138.01350\n",
      "Validation loss decreased (inf --> 138.013496).  Saving model ...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Got <class 'NoneType'>, but numpy array, torch tensor, or caffe2 blob name are expected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-727cefc2ad42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_early_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/primesh/F4D0EA80D0EA4906/PROJECTS/FYP/Gaze detection/code/ObjectGazeNet/gazefollowing/training/train_primesh.py\u001b[0m in \u001b[0;36mtrain_with_early_stopping\u001b[0;34m(model, train_data_loader, valid_data_loader, criterion, optimizer, logger, writer, num_epochs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name}.grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_histogram\u001b[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 430\u001b[0;31m             histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     def add_histogram_raw(self, tag, min, max, num, sum, sum_squares,\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, values, bins, max_bins)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.9/site-packages/torch/utils/tensorboard/_convert_np.py\u001b[0m in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_prepare_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m     26\u001b[0m         'Got {}, but numpy array, torch tensor, or caffe2 blob name are expected.'.format(type(x)))\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Got <class 'NoneType'>, but numpy array, torch tensor, or caffe2 blob name are expected."
     ]
    }
   ],
   "source": [
    "model_ft2 = train_with_early_stopping(model_ft2,train_data_loader, val_data_loader, criterion, optimizer, logger, writer,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
